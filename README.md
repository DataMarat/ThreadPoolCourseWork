# Кастомный пул потоков (Thread Pool)
Этот проект реализует собственный пул потоков для высоконагруженных приложений без использования ThreadPoolExecutor. Поддерживается конфигурируемое управление потоками, ограниченная очередь задач, логирование событий, и стратегия отказа при перегрузке.
Цель проекта — получить глубокое понимание принципов многопоточности, балансировки нагрузки и проектирования отказоустойчивых систем.

## Структура проекта


```agsl
ThreadPoolCourseWork/
├── pom.xml
├── README.md
└── src/
    └── main/
        ├── java/
        │   └── org/
        │       └── example/
        │           └── threadpool/
        │               ├── demo/
        │               │   └── Main.java                    # Демонстрационная программа
        │               │
        │               ├── executor/
        │               │   ├── CustomExecutor.java          # Интерфейс пула
        │               │   └── CustomThreadPool.java        # Основной класс пула
        │               │
        │               ├── internal/
        │               │   ├── Worker.java                  # Поток-исполнитель задач
        │               │   ├── ThreadFactoryImpl.java       # Фабрика именованных потоков
        │               │   └── TaskQueue.java               # Обёртка над очередью задач
        │               │
        │               └── policy/
        │                   ├── RejectionPolicy.java         # Интерфейс отказа при переполнении
        │                   └── AbortPolicy.java             # Реализация: отказ с логированием
        │
        └── resources/
            └── logback.xml (опционально)                    # Конфигурация логгера

```

## Анализ производительности

Для оценки эффективности собственного пула потоков была проведена практическая нагрузка и сравнительный анализ со стандартным `ThreadPoolExecutor` и промышленными решениями, такими как Tomcat и Jetty.

### Сравнение с `ThreadPoolExecutor` (JDK)

| Критерий                        | CustomThreadPool                             | ThreadPoolExecutor                        |
|----------------------------------|----------------------------------------------|-------------------------------------------|
| Гибкость настройки              | Полный контроль над очередью, потоками и логикой отказа | Хорошая, но с предопределённым поведением |
| Логирование                     | Полное, настраиваемое                        | Требует обёртки                            |
| Балансировка задач             | Round-robin/очередь                          | Очередь + внутренний планировщик          |
| Отказоустойчивость             | Зависит от политики (`AbortPolicy` и др.)   | Поддержка `RejectedExecutionHandler`      |
| Порог адаптивного масштабирования | Управляется вручную                         | Встроенное поведение                      |
| Наглядность и отладка          | Высокая, благодаря логам                     | Ограниченная, без дополнительных средств  |

**Вывод**: при учебных и исследовательских задачах кастомная реализация показывает лучшее понимание механики. В реальных проектах `ThreadPoolExecutor` предпочтительнее из-за высокой оптимизации и безопасности.

### Сравнение с Tomcat/Jetty

Обе серверные платформы используют собственные реализации пула потоков с расширенной поддержкой:

- **Tomcat** использует `org.apache.tomcat.util.threads.ThreadPoolExecutor` — модифицированный и адаптированный JDK-пул.
- **Jetty** применяет `QueuedThreadPool` — с балансировкой, адаптивной стратегией и thread affinity.

В отличие от них, текущая реализация работает с одной глобальной очередью (что упрощает архитектуру) 
и не использует оптимизации типа повторного использования потоков (reuse) или обработки I/O в рамках пула.
При этом данное решение демонстрирует наглядную структуру, простоту расширения и прозрачную логику управления.

## Исследование параметров производительности

В рамках демонстрационной программы были протестированы различные конфигурации параметров пула. Основная цель — выявить, какие настройки обеспечивают наибольшую пропускную способность при ограниченной нагрузке и избежать избыточного создания потоков.

### Методика

- Каждая задача симулирует нагрузку с помощью `Thread.sleep(3000)` и логирует начало/окончание.
- Общее число отправленных задач: 10.
- Измерялись количество отклонённых задач, число активных потоков и скорость завершения всех задач.
- Менялись параметры:
    - `corePoolSize`
    - `maxPoolSize`
    - `queueSize`
    - `keepAliveTime`
    - `minSpareThreads`

### Результаты

| Конфигурация                                  | Поведение                                             |
|----------------------------------------------|--------------------------------------------------------|
| `core=2`, `max=4`, `queue=5`, `keepAlive=5s` | На 10 задач: 9 обработаны, 1 отклонена, 4 потока созданы |
| `core=4`, `max=4`, `queue=2`, `keepAlive=5s` | 6 задач сразу обрабатываются, остальные — отклонены    |
| `core=2`, `max=6`, `queue=8`, `keepAlive=10s`| Все 10 задач обработаны, 6 потоков активно             |
| `core=1`, `max=2`, `queue=1`, `keepAlive=3s` | Часть задач отбрасывается, задержки, медленная обработка |

### Выводы

- Увеличение `queueSize` помогает при коротких задачах, но может вызывать задержки при длинных.
- `minSpareThreads` полезен для постоянной готовности к всплеску нагрузки.
- Слишком большой `keepAliveTime` замедляет высвобождение ресурсов.
- Значения `corePoolSize` и `maxPoolSize` следует подбирать с учётом типов задач (CPU-bound или IO-bound).

Рекомендуется начинать с равных значений `corePoolSize = maxPoolSize` и минимальной очереди, затем адаптировать под характер нагрузки.

## Принцип распределения задач и балансировки

В данной реализации используется **единая глобальная очередь задач** (`BlockingQueue<Runnable>`), общая для всех потоков-воркеров. Потоки самостоятельно извлекают задачи из очереди в порядке поступления (FIFO), обеспечивая тем самым равномерную загрузку.

### Алгоритм работы

1. Задача поступает в пул через `execute()` или `submit()`.
2. Если очередь не заполнена, задача помещается в неё.
3. При необходимости (например, если число свободных потоков меньше `minSpareThreads`) создаются дополнительные потоки до достижения `maxPoolSize`.
4. Потоки-воркеры блокирующе ожидают задачи через `poll()` с таймаутом.
5. Если поток простаивает дольше `keepAliveTime` и общее число потоков больше `corePoolSize`, он завершает работу.

### Почему не используется Round Robin или Least Loaded

Согласно требованиям курсовой, реализация балансировки через отдельные очереди или алгоритмы распределения задач (Round Robin, Least Loaded и пр.) **не является обязательной**. Для простоты и надёжности была выбрана модель с одной очередью, обеспечивающая достаточную сбалансированность в условиях умеренной нагрузки.

Тем не менее, архитектура допускает расширение к многим очередям и более сложным схемам планирования задач в будущем.
